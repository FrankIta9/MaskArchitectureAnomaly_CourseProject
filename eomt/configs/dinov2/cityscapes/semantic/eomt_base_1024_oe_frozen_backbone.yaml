# ============================================================================
# FROZEN BACKBONE + DECODER FINE-TUNING per Outlier Exposure
# ============================================================================
#
# STRATEGIA:
# - Backbone (ViT) CONGELATO → preserva feature semantiche Cityscapes
# - Solo decoder trainable (~10M params vs 95M) → fine-tuning leggero
# - LR più alto (5e-5) possibile perché solo decoder cambia
# - Training 10x più veloce, più stabile, zero rischio overfitting
#
# VANTAGGI:
# 1. Mantiene 100% mIoU Cityscapes (backbone intatto)
# 2. Decoder impara solo a riconoscere outliers COCO come "no object"
# 3. Convergenza rapida (poche epochs sufficienti)
# 4. Allineato con best practices OE (RbA paper)
#
# PARAMETRI TRAINABILI:
# - Scale blocks (cross-attention tra ViT e queries)
# - Learned queries (embeddings semantici)
# - Class head (classifica in-distribution vs "no object")
# - Mask head (genera maschere per ogni query)
#
# ============================================================================

trainer:
  max_epochs: 30  # Ridotto: convergenza più rapida con solo decoder
  
  # Batch size più grande possibile con decoder-only training
  accumulate_grad_batches: 1  # Effective = batch_size
  precision: "16-mixed"
  
  # Checkpoint su Google Drive
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "/content/drive/MyDrive/eomt_oe_frozen_backbone"
        filename: "eomt_frozen-{epoch:03d}-{metrics/val_iou_all:.4f}"
        monitor: "metrics/val_iou_all"
        mode: "max"
        save_top_k: 3
        save_last: true
        every_n_epochs: 1
  
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "OE_FrozenBackbone_lr5e6_LogitNorm_weightedScale"

model:
  class_path: training.mask_classification_semantic.MaskClassificationSemantic
  init_args:
    # Pesi Cityscapes puliti (riparti da capo con distribuzione pesata)
    ckpt_path: "/content/drive/MyDrive/eomt_cityscapes.bin"
    # IMPORTANTE: Riparti da pesi Cityscapes puliti (non da epoch 16) per evitare disimparamento
    # Con distribuzione pesata + parametri conservativi, il training sarà più stabile
    
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [3317, 8292, 13268]
    attn_mask_annealing_end_steps: [6634, 11609, 16585]
    
    # ===== LR BILANCIATO PER FROZEN BACKBONE + BATCH SIZE RIDOTTO =====
    # 5e-6 = compromesso tra 1e-6 (ultra-conservativo) e 1e-5 (più veloce ma instabile)
    # MOTIVAZIONE:
    # - Frozen backbone → decoder può tollerare LR più alto (best practices: 1e-4 per decoder)
    # - Batch size ridotto (2 vs 6 config funzionante) → LR più alto compensa effective batch size minore
    # - Energy Loss + Logit Norm → 5e-6 è più stabile di 1e-4 ma più veloce di 1e-6
    # - Energy warmup (epochs 0-9 disabled) → mitigazione instabilità iniziale
    # VALIDATO: config funzionante (RoadObstacle21 92%) aveva lr: 1e-6 con batch_size=6
    # Con batch_size=2, 5e-6 è appropriato per compensare effective batch size minore
    lr: 5e-6
    llrd: 0.8  # Ignorato (backbone frozen), ma lasciato per compatibility
    
    # ===== ENERGY OOD CON WARMUP =====
    # VALIDATO: energy_warmup_epochs=10 è OK per max_epochs=30 (33% del training)
    # Il config funzionante (RoadObstacle21 92%) aveva energy_warmup_epochs=10
    # Partendo da 0, il warmup graduale è essenziale per stabilità
    energy_ood_enabled: true
    energy_ood_max_weight: 0.002  # Conservative (validato: stesso del config funzionante)
    energy_warmup_epochs: 10  # VALIDATO: 10 epochs (33% di 30) come config funzionante
    energy_warmup_start_epoch: 0  # Partiamo da 0 (riparti da capo con energy warmup normale)
    # All'epoch 0 → adjusted=0 (<10) → Energy DISABLED fino a epoch 10 (come previsto)
    # Epochs 0-9: Energy DISABLED (solo OE + loss standard)
    # Epochs 10-30: Energy ATTIVATO gradualmente (cosine warmup 0→0.002)
    max_epochs: 30
    
    # ===== LOGIT NORMALIZATION ENABLED =====
    # Normalizza logits per migliorare calibrazione anomaly scores
    # VALIDATO: funzionava bene nel config che ha dato RoadObstacle21 92%
    logit_norm_enabled: true
    logit_norm_tau: 0.04
    logit_norm_eps: 1e-6
    
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 100
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2

data:
  class_path: datasets.cityscapes_semantic_with_oe.CityscapesSemanticWithOE
  init_args:
    path: "/content/drive/MyDrive/Cityscapes"
    
    # Batch size ridotto per limiti memoria VRAM
    batch_size: 2  # Ridotto da 6 per limiti memoria (config funzionante aveva batch_size=6)
    num_workers: 8
    
    img_size: [1024, 1024]
    num_classes: 19
    color_jitter_enabled: true
    scale_range: [0.5, 2.0]
    check_empty_targets: true
    
    # ===== OUTLIER EXPOSURE OTTIMIZZATO =====
    coco_path: "/content/drive/MyDrive/coco2017_zips"
    coco_split: "train2017"  # Usa train2017 per più varietà (gestiamo noi la distribuzione pesata)
    # MOTIVAZIONE: Con distribuzione pesata multi-scale e coco_min_area=1500 (più alto),
    # train2017 (~500k oggetti) è perfetto per più varietà controllata
    # Compensiamo coco_min_area più alto (1500 vs 800) con più varietà train2017
    # Vantaggi: ~500k oggetti validi vs ~18k (val2017) → molto più varietà senza problemi di stabilità
    # Con 1 oggetto/batch al 15%, uso ~445 oggetti/epoch → train2017 evita ripetizioni e migliora learning
    use_coco_zip: true
    
    # ===== DISTRIBUZIONE PESATA MULTI-SCALE BILANCIATA =====
    # ANALISI PARAMETRI FUNZIONANTI (RoadObstacle21 92% AUPRC, FPR 0.51%):
    # - paste_probability: 0.15 ✅ (stesso del config funzionante)
    # - min_scale: 0.08, max_scale: 0.15 (uniforme) → NOI: distribuzione pesata per matchare anomalie diverse
    # - coco_min_area: 1500 ✅ (CRITICO! config funzionante aveva 1500, non 800!)
    # - coco_split: val2017 (config funzionante) → NOI: train2017 per più varietà (compensato con coco_min_area=1500)
    #
    # PROBLEMA IDENTIFICATO: RoadObstacle21 stava disimparando PRIMA della distribuzione pesata
    # - RoadObstacle21: anomalie GRANDI/MEDIE (10-40%) → FPR@95TPR passato da 0.51% a 10.98% (20x peggioramento!)
    # - fs_static/LostFound: anomalie PICCOLISSIME (1-5%) → basso AUPRC
    # - RoadAnomaly: anomalie MISTE (5-40%) → migliorato (+1.84%)
    #
    # CAUSE PROBABILI DEL DISIMPARAMENTO:
    # 1. paste_probability: 0.20 (era 0.15) → TROPPO ALTO, confonde il modello ✅ CORRETTO: 0.15
    # 2. min_scale/max_scale: 0.03/0.08 (erano 0.08/0.15) → TROPPO PICCOLI per RoadObstacle21
    # 3. coco_min_area: 600 (era 1500!) → TROPPO BASSO, oggetti di bassa qualità ❌ CORRETTO: 1500
    # 4. train2017 SENZA distribuzione pesata → troppa varietà casuale senza controllo
    #
    # SOLUZIONE: Parametri VALIDATI + Distribuzione pesata BILANCIATA
    # - paste_probability: 0.15 (valore originale funzionante) ✅
    # - coco_min_area: 1500 (valore originale funzionante) ✅ CRITICO!
    # - Distribuzione pesata (35% piccoli, 35% medi, 30% grandi) CONTROLLA la varietà train2017
    # - Scale ranges ESTESI per matchare RoadObstacle21 (anomalie fino al 40%!): grandi fino a 0.25-0.30
    paste_probability: 0.15  # VALIDATO: stesso del config funzionante (RoadObstacle21 92%)
    min_objects: 1
    max_objects: 1           # VALIDATO: stesso del config funzionante (più stabile)
    
    # Distribuzione pesata multi-scale BILANCIATA (35% piccoli, 35% medi, 30% grandi)
    # Priorità a preservare RoadObstacle21 (30% grandi fino a 0.30) mentre miglioriamo fs_static/LostFound (35% piccoli)
    # IMPORTANTE: RoadObstacle21 ha anomalie fino al 40% → range grandi esteso a 0.10-0.30 (non solo 0.18!)
    use_weighted_scale: true  # Abilita distribuzione pesata bilanciata
    scale_ranges:
      - [0.02, 0.05]   # Piccoli: 2-5% immagine (35% prob) → matcha fs_static/LostFound anomalie piccolissime
      - [0.05, 0.10]   # Medi: 5-10% immagine (35% prob) → matcha RoadAnomaly piccole/medie
      - [0.10, 0.30]   # Grandi: 10-30% immagine (30% prob) → PRESERVA RoadObstacle21 (anomalie grandi fino a 40%!)
    scale_weights: [0.35, 0.35, 0.30]  # 35% piccoli, 35% medi, 30% grandi (BILANCIATO verso grandi)
    
    # Parametri legacy (ignorati se use_weighted_scale=true):
    min_scale: 0.08          # Ignorato se use_weighted_scale=true (valore originale funzionante)
    max_scale: 0.15          # Ignorato se use_weighted_scale=true (valore originale funzionante)
    coco_min_area: 1500      # CRITICO: VALIDATO dal config funzionante (RoadObstacle21 92%)
    # IMPORTANTE: coco_min_area=1500 è ESSENZIALE! Il config funzionante aveva 1500, non 800!
    # COCO standard: Small <1024px, Medium 1024-9216px, Large >9216px
    # 1500px è nella categoria "Medium" (ben definiti, non rumore) ✅
