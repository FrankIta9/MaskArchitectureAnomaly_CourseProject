# Configurazione FINALE per Anomaly Segmentation: Outlier Exposure PURO
# Energy OOD Loss DISABILITATO (conflitto con OE, causava divergenza)
# Segue approccio RbA paper: OE + loss standard + post-hoc methods
# Ottimizzata per A100 (40GB VRAM)

trainer:
  max_epochs: 50
  # A100: batch_size=4 + accumulation=2 per gestire memoria del backward pass
  # Backward pass usa PIÙ memoria del forward, serve accumulation
  accumulate_grad_batches: 2  # Effective batch_size = 4*2 = 8
  precision: "16-mixed"  # AMP per velocità
  
  # Checkpoint salvati su Google Drive
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "/content/drive/MyDrive/eomt_checkpoints"
        filename: "eomt_1024_coco_oe-{epoch:03d}-{metrics/val_iou_all:.4f}"
        monitor: "metrics/val_iou_all"  # Nome corretto della metrica mIoU
        mode: "max"
        save_top_k: 3
        save_last: true
        every_n_epochs: 1
  
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "cityscapes_eomt_1024_OE_PURE_lr1e5_FINAL"
model:
  class_path: training.mask_classification_semantic.MaskClassificationSemantic
  init_args:
    # IMPORTANTE: Aggiungi il path ai tuoi pesi pre-addestrati
    # Sostituisci /path/to/eomt_cityscapes.bin con il path reale
    ckpt_path: "/content/drive/MyDrive/eomt_cityscapes.bin"
    
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [3317, 8292, 13268]
    attn_mask_annealing_end_steps: [6634, 11609, 16585]
    
    # Learning rate ULTRA-BASSO per fine-tuning gentile
    # Preserva conoscenza pre-addestrata mentre OE insegna anomaly detection
    lr: 1e-5
    
    # ENERGY OOD LOSS DISABILITATO
    # Conflitto con Outlier Exposure: OE vuole "no object" per outlier,
    # Energy loss penalizza questo comportamento → divergenza
    # Soluzione: OE puro + post-hoc energy score all'inference
    energy_ood_enabled: false
    
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 100
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2
data:
  class_path: datasets.cityscapes_semantic_with_oe.CityscapesSemanticWithOE
  init_args:
    # Path al dataset Cityscapes
    path: "/content/drive/MyDrive/Cityscapes"
    
    # A100: batch_size ridotto per backward pass (usa più memoria del forward)
    # 4 immagini con accumulate=2 → effective batch_size=8
    # Backward pass richiede MOLTA più memoria con 1024x1024 images
    batch_size: 4
    num_workers: 8  # A100 ha CPU più potenti
    
    # IMPORTANTE: 1024x1024 per compatibilità con i pesi pre-addestrati
    img_size: [1024, 1024]
    
    num_classes: 19
    color_jitter_enabled: true
    scale_range: [0.5, 2.0]
    check_empty_targets: true
    
    # ===== CONFIGURAZIONE COCO OUTLIER EXPOSURE (Ottimizzata A100) =====
    # Path alla directory che contiene i file zip COCO
    # I file devono essere:
    #   - annotations_trainval2017.zip
    #   - train2017.zip
    #   - val2017.zip
    coco_path: "/content/drive/MyDrive/coco2017_zips"
    
    # A100: usa val2017 per OE più controllato (training instabile con train2017)
    coco_split: "val2017"
    
    # IMPORTANTE: true perché hai i file in formato zip
    use_coco_zip: true
    
    # Parametri OE OTTIMIZZATI per anomaly segmentation stabile
    # Approccio graduale: inizia conservativo, può intensificare dopo convergenza
    paste_probability: 0.25     # 25% batch ha outliers (bilanciato)
    min_objects: 1              # Min oggetti da incollare per immagine
    max_objects: 2              # Max 2 oggetti (evita sovraccarico)
    min_scale: 0.10             # Oggetti non troppo piccoli (10% immagine)
    max_scale: 0.20             # Oggetti moderati (20% immagine max)
    coco_min_area: 1200         # Solo oggetti ben definiti e visibili
