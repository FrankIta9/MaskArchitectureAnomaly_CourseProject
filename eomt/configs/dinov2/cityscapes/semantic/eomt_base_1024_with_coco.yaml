# Configurazione per Anomaly Segmentation con EIM Loss + COCO Outlier Exposure
# Ottimizzata per A100 (40GB VRAM) - Training veloce ed efficace
# Usa i pesi pre-addestrati eomt_cityscapes.bin (1024x1024) e COCO per Outlier Exposure

trainer:
  max_epochs: 107
  # A100: nessun gradient accumulation necessario, batch_size grande direttamente
  # Questo rende il training molto più veloce (no overhead di accumulation)
  precision: "16-mixed"  # AMP per velocità
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "cityscapes_semantic_eomt_base_1024_coco_oe_a100"
model:
  class_path: training.mask_classification_semantic.MaskClassificationSemantic
  init_args:
    # IMPORTANTE: Aggiungi il path ai tuoi pesi pre-addestrati
    # Sostituisci /path/to/eomt_cityscapes.bin con il path reale
    ckpt_path: "/content/drive/MyDrive/eomt_cityscapes.bin"
    
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [3317, 8292, 13268]
    attn_mask_annealing_end_steps: [6634, 11609, 16585]
    
    # Learning rate scalato per batch_size 12 (da 1e-4 con bs=8)
    # Uso sqrt(1.5) ≈ 1.22 scaling per batch_size 1.5x più grande
    lr: 1.2e-4
    
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 100
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2
data:
  class_path: datasets.cityscapes_semantic_with_oe.CityscapesSemanticWithOE
  init_args:
    # Path al dataset Cityscapes
    path: "/content/drive/MyDrive/Cityscapes"
    
    # A100: batch_size ottimizzato per 40GB VRAM
    # 12 immagini 1024x1024 con OE → training 6x più veloce rispetto a batch_size=2
    # (16 era troppo, causava OOM anche su A100)
    batch_size: 12
    num_workers: 8  # A100 ha CPU più potenti
    
    # IMPORTANTE: 1024x1024 per compatibilità con i pesi pre-addestrati
    img_size: [1024, 1024]
    
    num_classes: 19
    color_jitter_enabled: true
    scale_range: [0.5, 2.0]
    check_empty_targets: true
    
    # ===== CONFIGURAZIONE COCO OUTLIER EXPOSURE (Ottimizzata A100) =====
    # Path alla directory che contiene i file zip COCO
    # I file devono essere:
    #   - annotations_trainval2017.zip
    #   - train2017.zip
    #   - val2017.zip
    coco_path: "/content/drive/MyDrive/coco2017_zips"
    
    # A100: usa train2017 per maggiore diversità (118k immagini vs 5k di val)
    coco_split: "train2017"
    
    # IMPORTANTE: true perché hai i file in formato zip
    use_coco_zip: true
    
    # A100: parametri OE più aggressivi per migliore anomaly detection
    paste_probability: 0.6      # Più oggetti outlier → migliore generalizzazione
    min_objects: 1              # Min oggetti da incollare per immagine
    max_objects: 4              # Aumentato da 2 a 4 per più varietà
    min_scale: 0.05             # Oggetti anche più piccoli
    max_scale: 0.35             # Oggetti anche più grandi (35% dell'immagine)
    coco_min_area: 800          # Ridotto per includere più oggetti
