# Configurazione per Anomaly Segmentation con EIM Loss + COCO Outlier Exposure
# Usa i pesi pre-addestrati eomt_cityscapes.bin (1024x1024) e COCO per Outlier Exposure

trainer:
  max_epochs: 107
  # Accumula gradienti per simulare batch_size più grande (evita OOM)
  accumulate_grad_batches: 4
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "cityscapes_semantic_eomt_base_1024_coco_oe"
model:
  class_path: training.mask_classification_semantic.MaskClassificationSemantic
  init_args:
    # IMPORTANTE: Aggiungi il path ai tuoi pesi pre-addestrati
    # Sostituisci /path/to/eomt_cityscapes.bin con il path reale
    ckpt_path: "/content/drive/MyDrive/eomt_cityscapes.bin"
    
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [3317, 8292, 13268]
    attn_mask_annealing_end_steps: [6634, 11609, 16585]
    
    # Learning rate
    lr: 1e-4
    
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 100
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2
data:
  class_path: datasets.cityscapes_semantic_with_oe.CityscapesSemanticWithOE
  init_args:
    # Path al dataset Cityscapes
    path: "/content/drive/MyDrive/Cityscapes"
    
    # Batch size molto ridotto per immagini 1024x1024 con OE (evita OOM)
    # Con accumulate_grad_batches=4, effective batch size = 2*4 = 8
    batch_size: 2
    num_workers: 4
    
    # IMPORTANTE: 1024x1024 per compatibilità con i pesi pre-addestrati
    img_size: [1024, 1024]
    
    num_classes: 19
    color_jitter_enabled: true
    scale_range: [0.5, 2.0]
    check_empty_targets: true
    
    # ===== CONFIGURAZIONE COCO OUTLIER EXPOSURE =====
    # Path alla directory che contiene i file zip COCO
    # I file devono essere:
    #   - annotations_trainval2017.zip
    #   - train2017.zip
    #   - val2017.zip
    coco_path: "/content/drive/MyDrive/coco2017_zips"
    
    # Split COCO da usare (val2017 è più piccolo, train2017 ha più oggetti)
    coco_split: "val2017"  # o "train2017" per più dati
    
    # IMPORTANTE: true perché hai i file in formato zip
    use_coco_zip: true
    
    # Parametri Outlier Exposure (leggermente ridotti per memoria)
    paste_probability: 0.5      # Probabilità di applicare cut-paste (0.0-1.0)
    min_objects: 1              # Min oggetti da incollare per immagine
    max_objects: 2              # Max oggetti da incollare per immagine
    min_scale: 0.08             # Scala minima oggetti (8% dell'immagine)
    max_scale: 0.25             # Scala massima oggetti (25% dell'immagine)
    coco_min_area: 1000         # Area minima oggetti COCO in pixel
