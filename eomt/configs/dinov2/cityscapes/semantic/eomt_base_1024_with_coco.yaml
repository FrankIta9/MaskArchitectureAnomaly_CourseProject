# ============================================================================
# CONFIGURAZIONE FINALE: Outlier Exposure + Energy OOD con WARMUP SCHEDULER
# ============================================================================
#
# SOLUZIONE AL CONFLITTO OE/Energy:
# - Epochs 1-15: Energy DISABILITATO (weight=0), solo OE + loss standard
#   → Modello impara: COCO outliers = "no object" class
#   → Convergenza stabile, no conflitti
#
# - Epochs 16-50: Energy ATTIVATO gradualmente (cosine warmup 0→0.002)
#   → Modello raffina: separazione energia ID/OOD
#   → "No object" già appreso, energy non crea conflitto
#
# VANTAGGI:
# ✅ Evita divergenza (loss crescente) vista con energy immediato
# ✅ Preserva conoscenza Cityscapes (LR 1e-5 ultra-basso)
# ✅ OE insegna outlier detection, Energy raffina confidence
# ✅ Accademicamente solido (segue best practices)
# ✅ Post-hoc: Energy score per anomaly detection all'inference
#
# Ottimizzata per A100 (40GB VRAM)

trainer:
  max_epochs: 50
  # A100: batch_size=4 + accumulation=2 per gestire memoria del backward pass
  # Backward pass usa PIÙ memoria del forward, serve accumulation
  accumulate_grad_batches: 2  # Effective batch_size = 4*2 = 8
  precision: "16-mixed"  # AMP per velocità
  
  # Checkpoint salvati su Google Drive (nuova cartella per training pulito)
  # IMPORTANTE: save_weights_only=false per salvare anche optimizer state (permette resume)
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "/content/drive/MyDrive/eomt_checkpoints_warmup"
        filename: "eomt_1024_oe_energy_warmup-{epoch:03d}-{metrics/val_iou_all:.4f}"
        monitor: "metrics/val_iou_all"
        mode: "max"
        save_top_k: 3
        save_last: true
        save_weights_only: false  # IMPORTANTE: Salva anche optimizer state per permettere resume
        # Se save_weights_only=true, non puoi riprendere il training (solo pesi modello)
        # Se save_weights_only=false, puoi riprendere con --ckpt_path
        every_n_epochs: 1
  
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "FINAL_OE+Energy_Warmup_lr1e5_cleanWeights"
model:
  class_path: training.mask_classification_semantic.MaskClassificationSemantic
  init_args:
    # IMPORTANTE: Aggiungi il path ai tuoi pesi pre-addestrati
    # Sostituisci /path/to/eomt_cityscapes.bin con il path reale
    ckpt_path: "/content/drive/MyDrive/eomt_cityscapes.bin"
    
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [3317, 8292, 13268]
    attn_mask_annealing_end_steps: [6634, 11609, 16585]
    
    # Learning rate ULTRA-BASSO per fine-tuning gentile
    # Preserva conoscenza pre-addestrata mentre OE insegna anomaly detection
    lr: 1e-5
    
    # ===== ENERGY OOD LOSS CON WARMUP SCHEDULER =====
    # ABILITATO ma con strategia graduale per evitare conflitto con OE
    energy_ood_enabled: true
    energy_ood_max_weight: 0.002  # Max weight raggiunto dopo warmup (conservativo)
    energy_warmup_epochs: 15      # Epochs 1-15: energy DISABILITATO (weight=0)
    max_epochs: 50                # Total epochs (per warmup scheduler)
    
    # Come funziona:
    # - Epochs 1-15: energy_weight = 0.0 (solo OE + loss standard)
    # - Epochs 16-50: energy_weight aumenta 0.0 → 0.002 (cosine schedule)
    # Risultato: no conflitto, convergenza stabile + energy refinement
    
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 100
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2
data:
  class_path: datasets.cityscapes_semantic_with_oe.CityscapesSemanticWithOE
  init_args:
    # Path al dataset Cityscapes
    path: "/content/drive/MyDrive/Cityscapes"
    
    # A100: batch_size ridotto per backward pass (usa più memoria del forward)
    # 4 immagini con accumulate=2 → effective batch_size=8
    # Backward pass richiede MOLTA più memoria con 1024x1024 images
    batch_size: 4
    num_workers: 8  # A100 ha CPU più potenti
    
    # IMPORTANTE: 1024x1024 per compatibilità con i pesi pre-addestrati
    img_size: [1024, 1024]
    
    num_classes: 19
    color_jitter_enabled: true
    scale_range: [0.5, 2.0]
    check_empty_targets: true
    
    # ===== CONFIGURAZIONE COCO OUTLIER EXPOSURE (Ottimizzata A100) =====
    # Path alla directory che contiene i file zip COCO
    # I file devono essere:
    #   - annotations_trainval2017.zip
    #   - train2017.zip
    #   - val2017.zip
    coco_path: "/content/drive/MyDrive/coco2017_zips"
    
    # A100: usa val2017 per OE più controllato (training instabile con train2017)
    coco_split: "val2017"
    
    # IMPORTANTE: true perché hai i file in formato zip
    use_coco_zip: true
    
    # Parametri OE OTTIMIZZATI per anomaly segmentation stabile
    # Approccio graduale: inizia conservativo, può intensificare dopo convergenza
    paste_probability: 0.25     # 25% batch ha outliers (bilanciato)
    min_objects: 1              # Min oggetti da incollare per immagine
    max_objects: 2              # Max 2 oggetti (evita sovraccarico)
    min_scale: 0.10             # Oggetti non troppo piccoli (10% immagine)
    max_scale: 0.20             # Oggetti moderati (20% immagine max)
    coco_min_area: 1200         # Solo oggetti ben definiti e visibili
